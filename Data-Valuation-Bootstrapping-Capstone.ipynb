{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0197024",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbeae2f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T13:32:35.357821Z",
     "start_time": "2022-06-08T13:32:35.353200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffdc1c",
   "metadata": {},
   "source": [
    "# Code for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d707bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T13:32:36.599213Z",
     "start_time": "2022-06-08T13:32:36.561799Z"
    }
   },
   "outputs": [],
   "source": [
    "class Prep_Bdv_Experiments():\n",
    "    \"\"\"Class used to implement and experiment with bootstrap data values (bdv).\"\"\"\n",
    "    \n",
    "    ######## 1. Constructor ########\n",
    "    \n",
    "    def __init__(self, \n",
    "                 training_folds,\n",
    "                 acc_kind='in-model',\n",
    "                 clf=DecisionTreeClassifier(random_state=22), \n",
    "                 num_boot_samples=1000,\n",
    "                 remove=[0, 0.05, 0.10, 0.15],\n",
    "                 remove_kind= 'low'\n",
    "                ):\n",
    "        \"\"\"Create a new class instance.\n",
    "        \n",
    "        training_folds    training dataset (composed of k-folds); format: dataframe\n",
    "        acc_kind          kind of accuracy: in-model accuracy, out-model accuracy or accuracy difference (=bdv)\n",
    "        clf               a classifier e.g., decison tree\n",
    "        num_boot_samples  # bootstrap samples used for data valuation method\n",
    "        remove            % of data to be removed for thresholding experiments\n",
    "        bdv               bootstrap data values of all data points\n",
    "        my_train_data     training data used to build final classifier,i.e.,training data \n",
    "                          from which a certain % of data was removed (for thresholding experiment)\n",
    "        removed_data      data that was removed from training_folds to create my_train_data\n",
    "        \"\"\"\n",
    "        self._num_boot_samples = num_boot_samples\n",
    "        self._remove = remove\n",
    "        self._bdv = self.compute_bdv(training_folds, acc_kind, num_boot_samples, clf)\n",
    "        self._train_data_final_clf = self.compute_train_data_final_clf(training_folds, remove, remove_kind)\n",
    "        \n",
    "        \n",
    "    ######## 2. Access attributes ########\n",
    "    \n",
    "    def get_num_boot_samples(self):\n",
    "        return self._num_boot_samples \n",
    "    \n",
    "    def get_remove(self):\n",
    "        \"\"\"Return % of data to be removed from training data.\"\"\"\n",
    "        return self._remove\n",
    "    \n",
    "    def get_bdv(self):\n",
    "        \"\"\"Return bootstrap data values for each data point.\"\"\"\n",
    "        return self._bdv\n",
    "    \n",
    "    def get_train_data_final_clf(self):\n",
    "        \"\"\"Return processed training data for final classifier.\"\"\"\n",
    "        return self._train_data_final_clf\n",
    "  \n",
    "    \n",
    "    ######## 3. Compute Bootstrap Data Values ########\n",
    "    \n",
    "    # 3.1 Generate bootstrap samples and out-of-bag instances (oob)\n",
    "    def create_boot_and_oob(self, training_folds, num_boot_samples):\n",
    "        \n",
    "        all_boot_and_oob = []\n",
    "        \n",
    "        for i in range(num_boot_samples):\n",
    "            boot = resample(training_folds, replace = True)\n",
    "            oob = pd.DataFrame([training_folds.loc[x,:] for x in training_folds.index if x not in boot.index])\n",
    "        \n",
    "            boot_and_oob = (boot, oob)\n",
    "            all_boot_and_oob.append(boot_and_oob)\n",
    "            \n",
    "        return all_boot_and_oob\n",
    "            \n",
    "    \n",
    "    # 3.2 Compute Bootstrap Data Values (bdv)\n",
    "    def compute_bdv(self, training_folds, acc_kind, num_boot_samples, clf):\n",
    "        \n",
    "        all_boot_and_oob = self.create_boot_and_oob(training_folds, num_boot_samples)\n",
    "\n",
    "        bdv = [] #list of bootstrap data values or in-model or out-model accuracies\n",
    "        my_clf = clf\n",
    "        \n",
    "        for x in training_folds.index: # go through training_folds indices\n",
    "            in_model_acc = np.array([ ])\n",
    "            out_model_acc = np.array([ ])\n",
    "            for boot_oob_tuple in all_boot_and_oob:\n",
    "                #IF index (=x) is not in oob (=boot_oob_tuplet[1]) THEN compute in-model accuracy\n",
    "                if x not in boot_oob_tuple[1].index:\n",
    "                    # create training set from bootstrap sample\n",
    "                    X_train = boot_oob_tuple[0].iloc[:,:-1] \n",
    "                    y_train = boot_oob_tuple[0].iloc[:,-1] #last column: target\n",
    "                    \n",
    "                    # create test set from oob\n",
    "                    X_test = boot_oob_tuple[1].iloc[:,:-1]\n",
    "                    y_test = boot_oob_tuple[1].iloc[:,-1]\n",
    "                    \n",
    "                    # fit classifier\n",
    "                    my_clf.fit(X_train, y_train)\n",
    "                    # test classifier\n",
    "                    y_predicted_test =  my_clf.predict(X_test)\n",
    "                    #compute accuracy\n",
    "                    accuracy = accuracy_score(y_test,y_predicted_test)\n",
    "                    \n",
    "                    in_model_acc = np.append(in_model_acc, accuracy)\n",
    "       \n",
    "                #ELSE compute out-model accuracy \n",
    "                else: \n",
    "                    # create training set from bootstrap sample\n",
    "                    X_train = boot_oob_tuple[0].iloc[:,:-1] \n",
    "                    y_train = boot_oob_tuple[0].iloc[:,-1] #last column: target\n",
    "                    # create test set from oob\n",
    "                    X_test = boot_oob_tuple[1].iloc[:,:-1].drop(x) # remove target data point\n",
    "                    y_test = boot_oob_tuple[1].iloc[:,-1].drop(x) # remove target data point\n",
    "                    \n",
    "                    # fit classifier\n",
    "                    my_clf.fit(X_train, y_train)\n",
    "                    # test classifier\n",
    "                    y_predicted_test = my_clf.predict(X_test)\n",
    "                    #compute accuracy\n",
    "                    accuracy = accuracy_score(y_test,y_predicted_test)\n",
    "                    \n",
    "                    out_model_acc = np.append(out_model_acc, accuracy)\n",
    "                    \n",
    "            mean_in_model_acc = np.mean(in_model_acc) # in-model accuracy for instance x\n",
    "            mean_out_model_acc = np.mean(out_model_acc) # out-model accuracy for instance x\n",
    "            \n",
    "            # user selects type of accuracy needed for experiment\n",
    "            if acc_kind == 'difference': # difference = bootstrap data values\n",
    "                one_bdv = mean_in_model_acc - mean_out_model_acc \n",
    "                bdv.append(one_bdv)\n",
    "                \n",
    "            if acc_kind == 'in-model':\n",
    "                bdv.append(mean_in_model_acc)\n",
    "            \n",
    "            if acc_kind == 'out-model':\n",
    "                bdv.append(mean_out_model_acc)\n",
    "                 \n",
    "        return bdv\n",
    "    \n",
    "    ######## 4. Training Data for Final Classifier ########\n",
    "    \n",
    "    def add_bdv_to_df(self, training_folds): \n",
    "        \"\"\"Add bdv column to training_folds dataset before the target column.\"\"\"\n",
    "        new_data = training_folds.copy(deep = True)\n",
    "        new_data.insert(len(training_folds.columns)-1, 'Bootstrap Data Values', self._bdv)\n",
    "        return new_data\n",
    "    \n",
    "    def compute_train_data_final_clf(self, training_folds, remove, remove_kind):\n",
    "        \"\"\"Removes a certain % of data with lowest or highest bdv.\"\"\"\n",
    "        \n",
    "        all_removed_indexes = []\n",
    "        all_X_train_data_final_clf = []\n",
    "        all_y_train_data_final_clf = []\n",
    "        \n",
    "        dataset_with_bdv = self.add_bdv_to_df(training_folds)\n",
    "        \n",
    "        for i in range(len(remove)):\n",
    "            # compute number of rows to be removed\n",
    "            num_rows = len(dataset_with_bdv.index)\n",
    "            num_rows_remove = round(remove[i] * num_rows) # round number in case it is a fraction\n",
    "            \n",
    "            if remove_kind == 'low':\n",
    "                # sort indexes by bdv in ascending order\n",
    "                ranked_indexes = dataset_with_bdv.loc[:, 'Bootstrap Data Values'].sort_values(ascending=True).index\n",
    "                removed_indexes = ranked_indexes[:num_rows_remove]\n",
    "                \n",
    "            if remove_kind == 'high':\n",
    "                # sort indexes by bdv in descending order\n",
    "                ranked_indexes = dataset_with_bdv.loc[:, 'Bootstrap Data Values'].sort_values(ascending=False).index\n",
    "                removed_indexes = ranked_indexes[:num_rows_remove]\n",
    "            \n",
    "            #drop rows\n",
    "            train_data_final_clf = dataset_with_bdv.drop(columns = 'Bootstrap Data Values')\n",
    "            train_data_final_clf =  train_data_final_clf.drop(index=removed_indexes)\n",
    "            X_train_final_clf = train_data_final_clf.iloc[:,:-1]\n",
    "            y_train_final_clf = train_data_final_clf.iloc[:,-1]\n",
    "            \n",
    "            all_removed_indexes.append(removed_indexes)\n",
    "            all_X_train_data_final_clf.append(X_train_final_clf)\n",
    "            all_y_train_data_final_clf.append(y_train_final_clf)\n",
    "\n",
    "        \n",
    "        return all_X_train_data_final_clf, all_y_train_data_final_clf, all_removed_indexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
